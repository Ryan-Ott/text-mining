{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1-Assignment\n",
    "\n",
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL\n",
    "\n",
    "This notebook describes the assignment for Lab 1 of the text mining course. \n",
    "\n",
    "**Points**: each exercise is prefixed with the number of points you can obtain for the exercise.\n",
    "\n",
    "We assume you have worked through the following notebooks:\n",
    "* **Lab1.1-introduction**\n",
    "* **Lab1.2-introduction-to-NLTK**\n",
    "* **Lab1.3-introduction-to-spaCy** \n",
    "\n",
    "In this assignment, you will process an English text (**Lab1-apple-samsung-example.txt**) with both NLTK and spaCy and discuss the similarities and differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "The notebooks in this block have been originally created by [Marten Postma](https://martenpostma.github.io). Adaptations were made by [Filip Ilievski](http://ilievski.nl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip: how to read a file from disk\n",
    "Let's open the file **Lab1-apple-samsung-example.txt** from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ryan/Desktop/Edu/VU/Year3/TextMining/text-mining/lab_sessions/lab1/Lab1-apple-samsung-example.txt\n",
      "does path exist? -> True\n"
     ]
    }
   ],
   "source": [
    "cur_dir = Path().resolve() # this should provide you with the folder in which this notebook is placed\n",
    "path_to_file = Path.joinpath(cur_dir, 'Lab1-apple-samsung-example.txt')\n",
    "print(path_to_file)\n",
    "print('does path exist? ->', Path.exists(path_to_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the output from the code cell above states that **does path exist? -> False**, please check that the file **Lab1-apple-samsung-example.txt** is in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters 1139\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file) as infile:\n",
    "    text = infile.read()\n",
    "\n",
    "print('number of characters', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 4] Exercise 1: NLTK\n",
    "In this exercise, we use NLTK to apply **Part-of-speech (POS) tagging**, **Named Entity Recognition (NER)**, and **Constituency parsing**. The following code snippet already performs sentence splitting and tokenization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_nltk = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_sentence = []\n",
    "for sentence_nltk in sentences_nltk:\n",
    "    sent_tokens = word_tokenize(sentence_nltk)\n",
    "    tokens_per_sentence.append(sent_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use lists to keep track of the output of the NLP tasks. We can hence inspect the output for each task using the index of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE The six phones and tablets affected are the Galaxy S III, running the new Jelly Bean system, the Galaxy Tab 8.9 Wifi tablet, the Galaxy Tab 2 10.1, Galaxy Rugby Pro and Galaxy S III mini.\n",
      "TOKENS ['The', 'six', 'phones', 'and', 'tablets', 'affected', 'are', 'the', 'Galaxy', 'S', 'III', ',', 'running', 'the', 'new', 'Jelly', 'Bean', 'system', ',', 'the', 'Galaxy', 'Tab', '8.9', 'Wifi', 'tablet', ',', 'the', 'Galaxy', 'Tab', '2', '10.1', ',', 'Galaxy', 'Rugby', 'Pro', 'and', 'Galaxy', 'S', 'III', 'mini', '.']\n"
     ]
    }
   ],
   "source": [
    "sent_id = 1\n",
    "print('SENTENCE', sentences_nltk[sent_id])\n",
    "print('TOKENS', tokens_per_sentence[sent_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [point: 1] Exercise 1a: Part-of-speech (POS) tagging\n",
    "Use `nltk.pos_tag` to perform part-of-speech tagging on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags_per_sentence = []\n",
    "for token in tokens_per_sentence:\n",
    "    pos_tag = nltk.pos_tag(token)\n",
    "    pos_tags_per_sentence.append(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('https', 'NN'), (':', ':'), ('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ'), ('Documents', 'NNS'), ('filed', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('San', 'NNP'), ('Jose', 'NNP'), ('federal', 'JJ'), ('court', 'NN'), ('in', 'IN'), ('California', 'NNP'), ('on', 'IN'), ('November', 'NNP'), ('23', 'CD'), ('list', 'NN'), ('six', 'CD'), ('Samsung', 'NNP'), ('products', 'NNS'), ('running', 'VBG'), ('the', 'DT'), ('``', '``'), ('Jelly', 'RB'), ('Bean', 'NNP'), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), ('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP'), (\"''\", \"''\"), ('operating', 'VBG'), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), ('Apple', 'NNP'), ('claims', 'VBZ'), ('infringe', 'VB'), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')], [('The', 'DT'), ('six', 'CD'), ('phones', 'NNS'), ('and', 'CC'), ('tablets', 'NNS'), ('affected', 'VBN'), ('are', 'VBP'), ('the', 'DT'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), (',', ','), ('running', 'VBG'), ('the', 'DT'), ('new', 'JJ'), ('Jelly', 'NNP'), ('Bean', 'NNP'), ('system', 'NN'), (',', ','), ('the', 'DT'), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('8.9', 'CD'), ('Wifi', 'NNP'), ('tablet', 'NN'), (',', ','), ('the', 'DT'), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('2', 'CD'), ('10.1', 'CD'), (',', ','), ('Galaxy', 'NNP'), ('Rugby', 'NNP'), ('Pro', 'NNP'), ('and', 'CC'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), ('mini', 'NN'), ('.', '.')], [('Apple', 'NNP'), ('stated', 'VBD'), ('it', 'PRP'), ('had', 'VBD'), ('“', 'NNP'), ('acted', 'VBD'), ('quickly', 'RB'), ('and', 'CC'), ('diligently', 'RB'), (\"''\", \"''\"), ('in', 'IN'), ('order', 'NN'), ('to', 'TO'), ('``', '``'), ('determine', 'VB'), ('that', 'IN'), ('these', 'DT'), ('newly', 'RB'), ('released', 'VBN'), ('products', 'NNS'), ('do', 'VBP'), ('infringe', 'VB'), ('many', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('claims', 'NNS'), ('already', 'RB'), ('asserted', 'VBN'), ('by', 'IN'), ('Apple', 'NNP'), ('.', '.'), (\"''\", \"''\")], [('In', 'IN'), ('August', 'NNP'), (',', ','), ('Samsung', 'NNP'), ('lost', 'VBD'), ('a', 'DT'), ('US', 'NNP'), ('patent', 'NN'), ('case', 'NN'), ('to', 'TO'), ('Apple', 'NNP'), ('and', 'CC'), ('was', 'VBD'), ('ordered', 'VBN'), ('to', 'TO'), ('pay', 'VB'), ('its', 'PRP$'), ('rival', 'JJ'), ('$', '$'), ('1.05bn', 'CD'), ('(', '('), ('£0.66bn', 'NN'), (')', ')'), ('in', 'IN'), ('damages', 'NNS'), ('for', 'IN'), ('copying', 'VBG'), ('features', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('iPad', 'NN'), ('and', 'CC'), ('iPhone', 'NN'), ('in', 'IN'), ('its', 'PRP$'), ('Galaxy', 'NNP'), ('range', 'NN'), ('of', 'IN'), ('devices', 'NNS'), ('.', '.')], [('Samsung', 'NNP'), (',', ','), ('which', 'WDT'), ('is', 'VBZ'), ('the', 'DT'), ('world', 'NN'), (\"'s\", 'POS'), ('top', 'JJ'), ('mobile', 'NN'), ('phone', 'NN'), ('maker', 'NN'), (',', ','), ('is', 'VBZ'), ('appealing', 'VBG'), ('the', 'DT'), ('ruling', 'NN'), ('.', '.')], [('A', 'DT'), ('similar', 'JJ'), ('case', 'NN'), ('in', 'IN'), ('the', 'DT'), ('UK', 'NNP'), ('found', 'VBD'), ('in', 'IN'), ('Samsung', 'NNP'), (\"'s\", 'POS'), ('favour', 'NN'), ('and', 'CC'), ('ordered', 'VBD'), ('Apple', 'NNP'), ('to', 'TO'), ('publish', 'VB'), ('an', 'DT'), ('apology', 'NN'), ('making', 'VBG'), ('clear', 'JJ'), ('that', 'IN'), ('the', 'DT'), ('South', 'JJ'), ('Korean', 'JJ'), ('firm', 'NN'), ('had', 'VBD'), ('not', 'RB'), ('copied', 'VBN'), ('its', 'PRP$'), ('iPad', 'NN'), ('when', 'WRB'), ('designing', 'VBG'), ('its', 'PRP$'), ('own', 'JJ'), ('devices', 'NNS'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "print(pos_tags_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [point: 1] Exercise 1b: Named Entity Recognition (NER)\n",
    "Use `nltk.chunk.ne_chunk` to perform Named Entity Recognition (NER) on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags_per_sentence = []\n",
    "for pos_token in pos_tags_per_sentence:\n",
    "    ner_tag = nltk.ne_chunk(pos_token)\n",
    "    ner_tags_per_sentence.append(ner_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('S', [('https', 'NN'), (':', ':'), ('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ'), ('Documents', 'NNS'), ('filed', 'VBN'), ('to', 'TO'), ('the', 'DT'), Tree('ORGANIZATION', [('San', 'NNP'), ('Jose', 'NNP')]), ('federal', 'JJ'), ('court', 'NN'), ('in', 'IN'), Tree('GPE', [('California', 'NNP')]), ('on', 'IN'), ('November', 'NNP'), ('23', 'CD'), ('list', 'NN'), ('six', 'CD'), Tree('ORGANIZATION', [('Samsung', 'NNP')]), ('products', 'NNS'), ('running', 'VBG'), ('the', 'DT'), ('``', '``'), ('Jelly', 'RB'), Tree('GPE', [('Bean', 'NNP')]), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), ('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP'), (\"''\", \"''\"), ('operating', 'VBG'), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), Tree('PERSON', [('Apple', 'NNP')]), ('claims', 'VBZ'), ('infringe', 'VB'), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')]), Tree('S', [('The', 'DT'), ('six', 'CD'), ('phones', 'NNS'), ('and', 'CC'), ('tablets', 'NNS'), ('affected', 'VBN'), ('are', 'VBP'), ('the', 'DT'), Tree('ORGANIZATION', [('Galaxy', 'NNP')]), ('S', 'NNP'), ('III', 'NNP'), (',', ','), ('running', 'VBG'), ('the', 'DT'), ('new', 'JJ'), Tree('PERSON', [('Jelly', 'NNP'), ('Bean', 'NNP')]), ('system', 'NN'), (',', ','), ('the', 'DT'), Tree('ORGANIZATION', [('Galaxy', 'NNP')]), ('Tab', 'NNP'), ('8.9', 'CD'), ('Wifi', 'NNP'), ('tablet', 'NN'), (',', ','), ('the', 'DT'), Tree('ORGANIZATION', [('Galaxy', 'NNP')]), ('Tab', 'NNP'), ('2', 'CD'), ('10.1', 'CD'), (',', ','), Tree('PERSON', [('Galaxy', 'NNP'), ('Rugby', 'NNP'), ('Pro', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Galaxy', 'NNP'), ('S', 'NNP')]), ('III', 'NNP'), ('mini', 'NN'), ('.', '.')]), Tree('S', [Tree('PERSON', [('Apple', 'NNP')]), ('stated', 'VBD'), ('it', 'PRP'), ('had', 'VBD'), ('“', 'NNP'), ('acted', 'VBD'), ('quickly', 'RB'), ('and', 'CC'), ('diligently', 'RB'), (\"''\", \"''\"), ('in', 'IN'), ('order', 'NN'), ('to', 'TO'), ('``', '``'), ('determine', 'VB'), ('that', 'IN'), ('these', 'DT'), ('newly', 'RB'), ('released', 'VBN'), ('products', 'NNS'), ('do', 'VBP'), ('infringe', 'VB'), ('many', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('claims', 'NNS'), ('already', 'RB'), ('asserted', 'VBN'), ('by', 'IN'), Tree('PERSON', [('Apple', 'NNP')]), ('.', '.'), (\"''\", \"''\")]), Tree('S', [('In', 'IN'), Tree('GPE', [('August', 'NNP')]), (',', ','), Tree('PERSON', [('Samsung', 'NNP')]), ('lost', 'VBD'), ('a', 'DT'), Tree('GSP', [('US', 'NNP')]), ('patent', 'NN'), ('case', 'NN'), ('to', 'TO'), Tree('GPE', [('Apple', 'NNP')]), ('and', 'CC'), ('was', 'VBD'), ('ordered', 'VBN'), ('to', 'TO'), ('pay', 'VB'), ('its', 'PRP$'), ('rival', 'JJ'), ('$', '$'), ('1.05bn', 'CD'), ('(', '('), ('£0.66bn', 'NN'), (')', ')'), ('in', 'IN'), ('damages', 'NNS'), ('for', 'IN'), ('copying', 'VBG'), ('features', 'NNS'), ('of', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('iPad', 'NN')]), ('and', 'CC'), Tree('ORGANIZATION', [('iPhone', 'NN')]), ('in', 'IN'), ('its', 'PRP$'), Tree('GPE', [('Galaxy', 'NNP')]), ('range', 'NN'), ('of', 'IN'), ('devices', 'NNS'), ('.', '.')]), Tree('S', [Tree('GPE', [('Samsung', 'NNP')]), (',', ','), ('which', 'WDT'), ('is', 'VBZ'), ('the', 'DT'), ('world', 'NN'), (\"'s\", 'POS'), ('top', 'JJ'), ('mobile', 'NN'), ('phone', 'NN'), ('maker', 'NN'), (',', ','), ('is', 'VBZ'), ('appealing', 'VBG'), ('the', 'DT'), ('ruling', 'NN'), ('.', '.')]), Tree('S', [('A', 'DT'), ('similar', 'JJ'), ('case', 'NN'), ('in', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('UK', 'NNP')]), ('found', 'VBD'), ('in', 'IN'), Tree('GPE', [('Samsung', 'NNP')]), (\"'s\", 'POS'), ('favour', 'NN'), ('and', 'CC'), ('ordered', 'VBD'), Tree('PERSON', [('Apple', 'NNP')]), ('to', 'TO'), ('publish', 'VB'), ('an', 'DT'), ('apology', 'NN'), ('making', 'VBG'), ('clear', 'JJ'), ('that', 'IN'), ('the', 'DT'), Tree('LOCATION', [('South', 'JJ'), ('Korean', 'JJ')]), ('firm', 'NN'), ('had', 'VBD'), ('not', 'RB'), ('copied', 'VBN'), ('its', 'PRP$'), ('iPad', 'NN'), ('when', 'WRB'), ('designing', 'VBG'), ('its', 'PRP$'), ('own', 'JJ'), ('devices', 'NNS'), ('.', '.')])]\n"
     ]
    }
   ],
   "source": [
    "print(ner_tags_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 1c: Constituency parsing\n",
    "Use the `nltk.RegexpParser` to perform constituency parsing on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_parser = nltk.RegexpParser('''\n",
    "NP: {<DT>? <JJ>* <NN>*} # NP\n",
    "P: {<IN>}           # Preposition\n",
    "V: {<V.*>}          # Verb\n",
    "PP: {<P> <NP>}      # PP -> P NP\n",
    "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituency_output_per_sentence = []\n",
    "for sentence in ner_tags_per_sentence:\n",
    "    constituent_structure = constituent_parser.parse(sentence)\n",
    "    constituency_output_per_sentence.append(constituent_structure)\n",
    "    # constituent_structure.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('S', [Tree('NP', [('https', 'NN')]), (':', ':'), Tree('NP', [('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ')]), ('Documents', 'NNS'), Tree('VP', [Tree('V', [('filed', 'VBN')])]), ('to', 'TO'), Tree('NP', [('the', 'DT')]), Tree('ORGANIZATION', [('San', 'NNP'), ('Jose', 'NNP')]), Tree('NP', [('federal', 'JJ'), ('court', 'NN')]), Tree('P', [('in', 'IN')]), Tree('GPE', [('California', 'NNP')]), Tree('P', [('on', 'IN')]), ('November', 'NNP'), ('23', 'CD'), Tree('NP', [('list', 'NN')]), ('six', 'CD'), Tree('ORGANIZATION', [('Samsung', 'NNP')]), ('products', 'NNS'), Tree('VP', [Tree('V', [('running', 'VBG')]), Tree('NP', [('the', 'DT')])]), ('``', '``'), ('Jelly', 'RB'), Tree('GPE', [('Bean', 'NNP')]), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), ('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP'), (\"''\", \"''\"), Tree('VP', [Tree('V', [('operating', 'VBG')])]), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), Tree('PERSON', [('Apple', 'NNP')]), Tree('VP', [Tree('V', [('claims', 'VBZ')])]), Tree('VP', [Tree('V', [('infringe', 'VB')])]), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')]), Tree('S', [Tree('NP', [('The', 'DT')]), ('six', 'CD'), ('phones', 'NNS'), ('and', 'CC'), ('tablets', 'NNS'), Tree('VP', [Tree('V', [('affected', 'VBN')])]), Tree('VP', [Tree('V', [('are', 'VBP')]), Tree('NP', [('the', 'DT')])]), Tree('ORGANIZATION', [('Galaxy', 'NNP')]), ('S', 'NNP'), ('III', 'NNP'), (',', ','), Tree('VP', [Tree('V', [('running', 'VBG')]), Tree('NP', [('the', 'DT'), ('new', 'JJ')])]), Tree('PERSON', [('Jelly', 'NNP'), ('Bean', 'NNP')]), Tree('NP', [('system', 'NN')]), (',', ','), Tree('NP', [('the', 'DT')]), Tree('ORGANIZATION', [('Galaxy', 'NNP')]), ('Tab', 'NNP'), ('8.9', 'CD'), ('Wifi', 'NNP'), Tree('NP', [('tablet', 'NN')]), (',', ','), Tree('NP', [('the', 'DT')]), Tree('ORGANIZATION', [('Galaxy', 'NNP')]), ('Tab', 'NNP'), ('2', 'CD'), ('10.1', 'CD'), (',', ','), Tree('PERSON', [('Galaxy', 'NNP'), ('Rugby', 'NNP'), ('Pro', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Galaxy', 'NNP'), ('S', 'NNP')]), ('III', 'NNP'), Tree('NP', [('mini', 'NN')]), ('.', '.')]), Tree('S', [Tree('PERSON', [('Apple', 'NNP')]), Tree('VP', [Tree('V', [('stated', 'VBD')])]), ('it', 'PRP'), Tree('VP', [Tree('V', [('had', 'VBD')])]), ('“', 'NNP'), Tree('VP', [Tree('V', [('acted', 'VBD')])]), ('quickly', 'RB'), ('and', 'CC'), ('diligently', 'RB'), (\"''\", \"''\"), Tree('PP', [Tree('P', [('in', 'IN')]), Tree('NP', [('order', 'NN')])]), ('to', 'TO'), ('``', '``'), Tree('VP', [Tree('V', [('determine', 'VB')]), Tree('PP', [Tree('P', [('that', 'IN')]), Tree('NP', [('these', 'DT')])])]), ('newly', 'RB'), Tree('VP', [Tree('V', [('released', 'VBN')])]), ('products', 'NNS'), Tree('VP', [Tree('V', [('do', 'VBP')])]), Tree('VP', [Tree('V', [('infringe', 'VB')]), Tree('NP', [('many', 'JJ')]), Tree('PP', [Tree('P', [('of', 'IN')]), Tree('NP', [('the', 'DT'), ('same', 'JJ')])])]), ('claims', 'NNS'), ('already', 'RB'), Tree('VP', [Tree('V', [('asserted', 'VBN')])]), Tree('P', [('by', 'IN')]), Tree('PERSON', [('Apple', 'NNP')]), ('.', '.'), (\"''\", \"''\")]), Tree('S', [Tree('P', [('In', 'IN')]), Tree('GPE', [('August', 'NNP')]), (',', ','), Tree('PERSON', [('Samsung', 'NNP')]), Tree('VP', [Tree('V', [('lost', 'VBD')]), Tree('NP', [('a', 'DT')])]), Tree('GSP', [('US', 'NNP')]), Tree('NP', [('patent', 'NN'), ('case', 'NN')]), ('to', 'TO'), Tree('GPE', [('Apple', 'NNP')]), ('and', 'CC'), Tree('VP', [Tree('V', [('was', 'VBD')])]), Tree('VP', [Tree('V', [('ordered', 'VBN')])]), ('to', 'TO'), Tree('VP', [Tree('V', [('pay', 'VB')])]), ('its', 'PRP$'), Tree('NP', [('rival', 'JJ')]), ('$', '$'), ('1.05bn', 'CD'), ('(', '('), Tree('NP', [('£0.66bn', 'NN')]), (')', ')'), Tree('P', [('in', 'IN')]), ('damages', 'NNS'), Tree('P', [('for', 'IN')]), Tree('VP', [Tree('V', [('copying', 'VBG')])]), ('features', 'NNS'), Tree('PP', [Tree('P', [('of', 'IN')]), Tree('NP', [('the', 'DT')])]), Tree('ORGANIZATION', [('iPad', 'NN')]), ('and', 'CC'), Tree('ORGANIZATION', [('iPhone', 'NN')]), Tree('P', [('in', 'IN')]), ('its', 'PRP$'), Tree('GPE', [('Galaxy', 'NNP')]), Tree('NP', [('range', 'NN')]), Tree('P', [('of', 'IN')]), ('devices', 'NNS'), ('.', '.')]), Tree('S', [Tree('GPE', [('Samsung', 'NNP')]), (',', ','), ('which', 'WDT'), Tree('VP', [Tree('V', [('is', 'VBZ')]), Tree('NP', [('the', 'DT'), ('world', 'NN')])]), (\"'s\", 'POS'), Tree('NP', [('top', 'JJ'), ('mobile', 'NN'), ('phone', 'NN'), ('maker', 'NN')]), (',', ','), Tree('VP', [Tree('V', [('is', 'VBZ')])]), Tree('VP', [Tree('V', [('appealing', 'VBG')]), Tree('NP', [('the', 'DT'), ('ruling', 'NN')])]), ('.', '.')]), Tree('S', [Tree('NP', [('A', 'DT'), ('similar', 'JJ'), ('case', 'NN')]), Tree('PP', [Tree('P', [('in', 'IN')]), Tree('NP', [('the', 'DT')])]), Tree('ORGANIZATION', [('UK', 'NNP')]), Tree('VP', [Tree('V', [('found', 'VBD')])]), Tree('P', [('in', 'IN')]), Tree('GPE', [('Samsung', 'NNP')]), (\"'s\", 'POS'), Tree('NP', [('favour', 'NN')]), ('and', 'CC'), Tree('VP', [Tree('V', [('ordered', 'VBD')])]), Tree('PERSON', [('Apple', 'NNP')]), ('to', 'TO'), Tree('VP', [Tree('V', [('publish', 'VB')]), Tree('NP', [('an', 'DT'), ('apology', 'NN')])]), Tree('VP', [Tree('V', [('making', 'VBG')]), Tree('NP', [('clear', 'JJ')]), Tree('PP', [Tree('P', [('that', 'IN')]), Tree('NP', [('the', 'DT')])])]), Tree('LOCATION', [('South', 'JJ'), ('Korean', 'JJ')]), Tree('NP', [('firm', 'NN')]), Tree('VP', [Tree('V', [('had', 'VBD')])]), ('not', 'RB'), Tree('VP', [Tree('V', [('copied', 'VBN')])]), ('its', 'PRP$'), Tree('NP', [('iPad', 'NN')]), ('when', 'WRB'), Tree('VP', [Tree('V', [('designing', 'VBG')])]), ('its', 'PRP$'), Tree('NP', [('own', 'JJ')]), ('devices', 'NNS'), ('.', '.')])]\n"
     ]
    }
   ],
   "source": [
    "print(constituency_output_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the RegexpParser so that it also detects Named Entity Phrases (NEP), e.g., that it detects *Galaxy S III* and *Ice Cream Sandwich*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_parser_v2 = nltk.RegexpParser('''\n",
    "NP: {<DT>? <JJ>* <NN>*} # NP\n",
    "P: {<IN>}                   # Preposition\n",
    "V: {<V.*>}                  # Verb\n",
    "PP: {<P> <NP>}              # PP -> P NP\n",
    "VP: {<V> <NP|PP>*}          # VP -> V (NP|PP)*\n",
    "NEP: {<NNP> <NNP> <NNP>*}   # NEP -> NNP NNP NNP*''')  # third one is optional because some entities are only two words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituency_v2_output_per_sentence = []\n",
    "for sentence in ner_tags_per_sentence:\n",
    "    constituency_v2_output = constituent_parser_v2.parse(sentence)\n",
    "    constituency_v2_output_per_sentence.append(constituency_v2_output)\n",
    "    # constituency_v2_output.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('S', [Tree('NP', [('https', 'NN')]), (':', ':'), Tree('NP', [('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ')]), ('Documents', 'NNS'), Tree('VP', [Tree('V', [('filed', 'VBN')])]), ('to', 'TO'), Tree('NP', [('the', 'DT')]), Tree('ORGANIZATION', [('San', 'NNP'), ('Jose', 'NNP')]), Tree('NP', [('federal', 'JJ'), ('court', 'NN')]), Tree('P', [('in', 'IN')]), Tree('GPE', [('California', 'NNP')]), Tree('P', [('on', 'IN')]), ('November', 'NNP'), ('23', 'CD'), Tree('NP', [('list', 'NN')]), ('six', 'CD'), Tree('ORGANIZATION', [('Samsung', 'NNP')]), ('products', 'NNS'), Tree('VP', [Tree('V', [('running', 'VBG')]), Tree('NP', [('the', 'DT')])]), ('``', '``'), ('Jelly', 'RB'), Tree('GPE', [('Bean', 'NNP')]), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), Tree('NEP', [('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP')]), (\"''\", \"''\"), Tree('VP', [Tree('V', [('operating', 'VBG')])]), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), Tree('PERSON', [('Apple', 'NNP')]), Tree('VP', [Tree('V', [('claims', 'VBZ')])]), Tree('VP', [Tree('V', [('infringe', 'VB')])]), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')]), Tree('S', [Tree('NP', [('The', 'DT')]), ('six', 'CD'), ('phones', 'NNS'), ('and', 'CC'), ('tablets', 'NNS'), Tree('VP', [Tree('V', [('affected', 'VBN')])]), Tree('VP', [Tree('V', [('are', 'VBP')]), Tree('NP', [('the', 'DT')])]), Tree('ORGANIZATION', [('Galaxy', 'NNP')]), Tree('NEP', [('S', 'NNP'), ('III', 'NNP')]), (',', ','), Tree('VP', [Tree('V', [('running', 'VBG')]), Tree('NP', [('the', 'DT'), ('new', 'JJ')])]), Tree('PERSON', [('Jelly', 'NNP'), ('Bean', 'NNP')]), Tree('NP', [('system', 'NN')]), (',', ','), Tree('NP', [('the', 'DT')]), Tree('ORGANIZATION', [('Galaxy', 'NNP')]), ('Tab', 'NNP'), ('8.9', 'CD'), ('Wifi', 'NNP'), Tree('NP', [('tablet', 'NN')]), (',', ','), Tree('NP', [('the', 'DT')]), Tree('ORGANIZATION', [('Galaxy', 'NNP')]), ('Tab', 'NNP'), ('2', 'CD'), ('10.1', 'CD'), (',', ','), Tree('PERSON', [('Galaxy', 'NNP'), ('Rugby', 'NNP'), ('Pro', 'NNP')]), ('and', 'CC'), Tree('PERSON', [('Galaxy', 'NNP'), ('S', 'NNP')]), ('III', 'NNP'), Tree('NP', [('mini', 'NN')]), ('.', '.')]), Tree('S', [Tree('PERSON', [('Apple', 'NNP')]), Tree('VP', [Tree('V', [('stated', 'VBD')])]), ('it', 'PRP'), Tree('VP', [Tree('V', [('had', 'VBD')])]), ('“', 'NNP'), Tree('VP', [Tree('V', [('acted', 'VBD')])]), ('quickly', 'RB'), ('and', 'CC'), ('diligently', 'RB'), (\"''\", \"''\"), Tree('PP', [Tree('P', [('in', 'IN')]), Tree('NP', [('order', 'NN')])]), ('to', 'TO'), ('``', '``'), Tree('VP', [Tree('V', [('determine', 'VB')]), Tree('PP', [Tree('P', [('that', 'IN')]), Tree('NP', [('these', 'DT')])])]), ('newly', 'RB'), Tree('VP', [Tree('V', [('released', 'VBN')])]), ('products', 'NNS'), Tree('VP', [Tree('V', [('do', 'VBP')])]), Tree('VP', [Tree('V', [('infringe', 'VB')]), Tree('NP', [('many', 'JJ')]), Tree('PP', [Tree('P', [('of', 'IN')]), Tree('NP', [('the', 'DT'), ('same', 'JJ')])])]), ('claims', 'NNS'), ('already', 'RB'), Tree('VP', [Tree('V', [('asserted', 'VBN')])]), Tree('P', [('by', 'IN')]), Tree('PERSON', [('Apple', 'NNP')]), ('.', '.'), (\"''\", \"''\")]), Tree('S', [Tree('P', [('In', 'IN')]), Tree('GPE', [('August', 'NNP')]), (',', ','), Tree('PERSON', [('Samsung', 'NNP')]), Tree('VP', [Tree('V', [('lost', 'VBD')]), Tree('NP', [('a', 'DT')])]), Tree('GSP', [('US', 'NNP')]), Tree('NP', [('patent', 'NN'), ('case', 'NN')]), ('to', 'TO'), Tree('GPE', [('Apple', 'NNP')]), ('and', 'CC'), Tree('VP', [Tree('V', [('was', 'VBD')])]), Tree('VP', [Tree('V', [('ordered', 'VBN')])]), ('to', 'TO'), Tree('VP', [Tree('V', [('pay', 'VB')])]), ('its', 'PRP$'), Tree('NP', [('rival', 'JJ')]), ('$', '$'), ('1.05bn', 'CD'), ('(', '('), Tree('NP', [('£0.66bn', 'NN')]), (')', ')'), Tree('P', [('in', 'IN')]), ('damages', 'NNS'), Tree('P', [('for', 'IN')]), Tree('VP', [Tree('V', [('copying', 'VBG')])]), ('features', 'NNS'), Tree('PP', [Tree('P', [('of', 'IN')]), Tree('NP', [('the', 'DT')])]), Tree('ORGANIZATION', [('iPad', 'NN')]), ('and', 'CC'), Tree('ORGANIZATION', [('iPhone', 'NN')]), Tree('P', [('in', 'IN')]), ('its', 'PRP$'), Tree('GPE', [('Galaxy', 'NNP')]), Tree('NP', [('range', 'NN')]), Tree('P', [('of', 'IN')]), ('devices', 'NNS'), ('.', '.')]), Tree('S', [Tree('GPE', [('Samsung', 'NNP')]), (',', ','), ('which', 'WDT'), Tree('VP', [Tree('V', [('is', 'VBZ')]), Tree('NP', [('the', 'DT'), ('world', 'NN')])]), (\"'s\", 'POS'), Tree('NP', [('top', 'JJ'), ('mobile', 'NN'), ('phone', 'NN'), ('maker', 'NN')]), (',', ','), Tree('VP', [Tree('V', [('is', 'VBZ')])]), Tree('VP', [Tree('V', [('appealing', 'VBG')]), Tree('NP', [('the', 'DT'), ('ruling', 'NN')])]), ('.', '.')]), Tree('S', [Tree('NP', [('A', 'DT'), ('similar', 'JJ'), ('case', 'NN')]), Tree('PP', [Tree('P', [('in', 'IN')]), Tree('NP', [('the', 'DT')])]), Tree('ORGANIZATION', [('UK', 'NNP')]), Tree('VP', [Tree('V', [('found', 'VBD')])]), Tree('P', [('in', 'IN')]), Tree('GPE', [('Samsung', 'NNP')]), (\"'s\", 'POS'), Tree('NP', [('favour', 'NN')]), ('and', 'CC'), Tree('VP', [Tree('V', [('ordered', 'VBD')])]), Tree('PERSON', [('Apple', 'NNP')]), ('to', 'TO'), Tree('VP', [Tree('V', [('publish', 'VB')]), Tree('NP', [('an', 'DT'), ('apology', 'NN')])]), Tree('VP', [Tree('V', [('making', 'VBG')]), Tree('NP', [('clear', 'JJ')]), Tree('PP', [Tree('P', [('that', 'IN')]), Tree('NP', [('the', 'DT')])])]), Tree('LOCATION', [('South', 'JJ'), ('Korean', 'JJ')]), Tree('NP', [('firm', 'NN')]), Tree('VP', [Tree('V', [('had', 'VBD')])]), ('not', 'RB'), Tree('VP', [Tree('V', [('copied', 'VBN')])]), ('its', 'PRP$'), Tree('NP', [('iPad', 'NN')]), ('when', 'WRB'), Tree('VP', [Tree('V', [('designing', 'VBG')])]), ('its', 'PRP$'), Tree('NP', [('own', 'JJ')]), ('devices', 'NNS'), ('.', '.')])]\n"
     ]
    }
   ],
   "source": [
    "print(constituency_v2_output_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 1] Exercise 2: spaCy\n",
    "Use Spacy to process the same text as you analyzed with NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'NNS', 'TIME'), ('\\n\\n', '_SP', ''), ('Documents', 'NNS', ''), ('filed', 'VBD', ''), ('to', 'IN', ''), ('the', 'DT', ''), ('San', 'NNP', 'GPE'), ('Jose', 'NNP', 'GPE'), ('federal', 'JJ', ''), ('court', 'NN', ''), ('in', 'IN', ''), ('California', 'NNP', 'GPE'), ('on', 'IN', ''), ('November', 'NNP', 'DATE'), ('23', 'CD', 'DATE'), ('list', 'NN', ''), ('six', 'CD', 'CARDINAL'), ('Samsung', 'NNP', 'ORG'), ('products', 'NNS', ''), ('running', 'VBG', ''), ('the', 'DT', 'LAW'), ('\"', '``', 'LAW'), ('Jelly', 'NNP', 'LAW'), ('Bean', 'NNP', 'LAW'), ('\"', \"''\", ''), ('and', 'CC', ''), ('\"', '``', ''), ('Ice', 'NNP', ''), ('Cream', 'NNP', ''), ('Sandwich', 'NN', ''), ('\"', \"''\", ''), ('operating', 'NN', ''), ('systems', 'NNS', ''), (',', ',', ''), ('which', 'WDT', ''), ('Apple', 'NNP', 'ORG'), ('claims', 'VBZ', ''), ('infringe', 'VBP', ''), ('its', 'PRP$', ''), ('patents', 'NNS', ''), ('.', '.', ''), ('\\n', '_SP', '')], [('The', 'DT', ''), ('six', 'CD', 'CARDINAL'), ('phones', 'NNS', ''), ('and', 'CC', ''), ('tablets', 'NNS', ''), ('affected', 'VBN', ''), ('are', 'VBP', ''), ('the', 'DT', 'ORG'), ('Galaxy', 'NNP', 'ORG'), ('S', 'NNP', 'ORG'), ('III', 'NNP', 'ORG'), (',', ',', ''), ('running', 'VBG', ''), ('the', 'DT', ''), ('new', 'JJ', ''), ('Jelly', 'NNP', 'ORG'), ('Bean', 'NNP', 'ORG'), ('system', 'NN', ''), (',', ',', ''), ('the', 'DT', ''), ('Galaxy', 'NNP', ''), ('Tab', 'NNP', ''), ('8.9', 'CD', 'CARDINAL'), ('Wifi', 'NNP', ''), ('tablet', 'NN', ''), (',', ',', ''), ('the', 'DT', ''), ('Galaxy', 'NNP', ''), ('Tab', 'NNP', ''), ('2', 'CD', 'DATE'), ('10.1', 'CD', 'DATE'), (',', ',', ''), ('Galaxy', 'NNP', 'ORG'), ('Rugby', 'NNP', 'ORG'), ('Pro', 'NNP', 'ORG'), ('and', 'CC', ''), ('Galaxy', 'NNP', 'PERSON'), ('S', 'NNP', 'PERSON'), ('III', 'NNP', 'PERSON'), ('mini', 'NN', ''), ('.', '.', ''), ('\\n', '_SP', '')], [('Apple', 'NNP', 'ORG'), ('stated', 'VBD', ''), ('it', 'PRP', ''), ('had', 'VBD', ''), ('“', '``', ''), ('acted', 'VBN', ''), ('quickly', 'RB', ''), ('and', 'CC', ''), ('diligently', 'RB', ''), ('\"', \"''\", ''), ('in', 'IN', ''), ('order', 'NN', ''), ('to', 'TO', ''), ('\"', '``', ''), ('determine', 'VB', ''), ('that', 'IN', ''), ('these', 'DT', ''), ('newly', 'RB', ''), ('released', 'VBN', ''), ('products', 'NNS', ''), ('do', 'VBP', ''), ('infringe', 'VB', ''), ('many', 'JJ', ''), ('of', 'IN', ''), ('the', 'DT', ''), ('same', 'JJ', ''), ('claims', 'NNS', ''), ('already', 'RB', ''), ('asserted', 'VBN', ''), ('by', 'IN', ''), ('Apple', 'NNP', 'ORG'), ('.', '.', '')], [('\"', \"''\", ''), ('\\n', '_SP', ''), ('In', 'IN', ''), ('August', 'NNP', 'DATE'), (',', ',', ''), ('Samsung', 'NNP', 'ORG'), ('lost', 'VBD', ''), ('a', 'DT', ''), ('US', 'NNP', 'GPE'), ('patent', 'NN', ''), ('case', 'NN', ''), ('to', 'IN', ''), ('Apple', 'NNP', 'ORG'), ('and', 'CC', ''), ('was', 'VBD', ''), ('ordered', 'VBN', ''), ('to', 'TO', ''), ('pay', 'VB', ''), ('its', 'PRP$', ''), ('rival', 'NN', ''), ('$', '$', ''), ('1.05bn', 'CD', 'MONEY'), ('(', '-LRB-', ''), ('£', '$', ''), ('0.66bn', 'NN', 'MONEY'), (')', '-RRB-', ''), ('in', 'IN', ''), ('damages', 'NNS', ''), ('for', 'IN', ''), ('copying', 'VBG', ''), ('features', 'NNS', ''), ('of', 'IN', ''), ('the', 'DT', ''), ('iPad', 'NNP', 'ORG'), ('and', 'CC', ''), ('iPhone', 'NNP', ''), ('in', 'IN', ''), ('its', 'PRP$', ''), ('Galaxy', 'NNP', 'FAC'), ('range', 'NN', ''), ('of', 'IN', ''), ('devices', 'NNS', ''), ('.', '.', '')], [('Samsung', 'NNP', 'ORG'), (',', ',', ''), ('which', 'WDT', ''), ('is', 'VBZ', ''), ('the', 'DT', ''), ('world', 'NN', ''), (\"'s\", 'POS', ''), ('top', 'JJ', ''), ('mobile', 'JJ', ''), ('phone', 'NN', ''), ('maker', 'NN', ''), (',', ',', ''), ('is', 'VBZ', ''), ('appealing', 'VBG', ''), ('the', 'DT', ''), ('ruling', 'NN', ''), ('.', '.', ''), ('\\n', '_SP', '')], [('A', 'DT', ''), ('similar', 'JJ', ''), ('case', 'NN', ''), ('in', 'IN', ''), ('the', 'DT', ''), ('UK', 'NNP', 'GPE'), ('found', 'VBN', ''), ('in', 'IN', ''), ('Samsung', 'NNP', 'ORG'), (\"'s\", 'POS', ''), ('favour', 'NN', ''), ('and', 'CC', ''), ('ordered', 'VBD', ''), ('Apple', 'NNP', 'ORG'), ('to', 'TO', ''), ('publish', 'VB', ''), ('an', 'DT', ''), ('apology', 'NN', ''), ('making', 'VBG', ''), ('clear', 'JJ', ''), ('that', 'IN', ''), ('the', 'DT', ''), ('South', 'JJ', 'NORP'), ('Korean', 'JJ', 'NORP'), ('firm', 'NN', ''), ('had', 'VBD', ''), ('not', 'RB', ''), ('copied', 'VBN', ''), ('its', 'PRP$', ''), ('iPad', 'NNP', 'ORG'), ('when', 'WRB', ''), ('designing', 'VBG', ''), ('its', 'PRP$', ''), ('own', 'JJ', ''), ('devices', 'NNS', ''), ('.', '.', '')]]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "tokens_per_sentence2 = []\n",
    "pos_tags_per_sentence2 = []\n",
    "ner_tags_per_sentence2 = []\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    tokens = [token.text for token in sentence]  # tokenisation\n",
    "    tokens_per_sentence2.append(tokens)\n",
    "\n",
    "    pos_tags = [token.tag_ for token in sentence]  # part-of-speech tagging\n",
    "    pos_tags_per_sentence2.append(pos_tags)\n",
    "    \n",
    "    ner_tags = [token.ent_type_ for token in sentence]  # named entity recognition\n",
    "    ner_tags_per_sentence2.append(ner_tags)\n",
    "\n",
    "tagged_tokens = []  # combining the pos_tags and ner_tags with the tokens to print them like in the nltk example\n",
    "for tokens, pos_tags, ner_tags in zip(tokens_per_sentence2, pos_tags_per_sentence2, ner_tags_per_sentence2):\n",
    "    triplet = list(zip(tokens, pos_tags, ner_tags))\n",
    "    tagged_tokens.append(triplet)\n",
    "\n",
    "print(tagged_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small tip: You can use **sents = list(doc.sents)** to be able to use the index to access a sentence like **sents[2]** for the third sentence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 7] Exercise 3: Comparison NLTK and spaCy\n",
    "We will now compare the output of NLTK and spaCy, i.e., in what do they differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 3] Exercise 3a: Part of speech tagging\n",
    "Compare the output from NLTK and spaCy regarding part of speech tagging.\n",
    "\n",
    "* To compare, you probably would like to compare sentence per sentence. Describe if the sentence splitting is different for NLTK than for spaCy. If not, where do they differ?\n",
    "* After checking the sentence splitting, select a sentence for which you expect interesting results and perhaps differences. Motivate your choice.\n",
    "* Compare the output in `token.tag` from spaCy to the part of speech tagging from NLTK for each token in your selected sentence. Are there any differences? This is not a trick question; it is possible that there are no differences."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.a.i - Is Sentence Splitting Different Between the Two?\n",
    "The below code shows that the sentence splitting between NLTK and spaCy is exactly the same. Even the first sentence with the URL is split in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE 0\n",
      "NLTK\n",
      "https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html\n",
      "\n",
      "Documents filed to the San Jose federal court in California on November 23 list six Samsung products running the \"Jelly Bean\" and \"Ice Cream Sandwich\" operating systems, which Apple claims infringe its patents.\n",
      "SPACY\n",
      "https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html\n",
      "\n",
      "Documents filed to the San Jose federal court in California on November 23 list six Samsung products running the \"Jelly Bean\" and \"Ice Cream Sandwich\" operating systems, which Apple claims infringe its patents.\n",
      "\n",
      "\n",
      "SENTENCE 1\n",
      "NLTK\n",
      "The six phones and tablets affected are the Galaxy S III, running the new Jelly Bean system, the Galaxy Tab 8.9 Wifi tablet, the Galaxy Tab 2 10.1, Galaxy Rugby Pro and Galaxy S III mini.\n",
      "SPACY\n",
      "The six phones and tablets affected are the Galaxy S III, running the new Jelly Bean system, the Galaxy Tab 8.9 Wifi tablet, the Galaxy Tab 2 10.1, Galaxy Rugby Pro and Galaxy S III mini.\n",
      "\n",
      "\n",
      "SENTENCE 2\n",
      "NLTK\n",
      "Apple stated it had “acted quickly and diligently\" in order to \"determine that these newly released products do infringe many of the same claims already asserted by Apple.\"\n",
      "SPACY\n",
      "Apple stated it had “acted quickly and diligently\" in order to \"determine that these newly released products do infringe many of the same claims already asserted by Apple.\n",
      "\n",
      "SENTENCE 3\n",
      "NLTK\n",
      "In August, Samsung lost a US patent case to Apple and was ordered to pay its rival $1.05bn (£0.66bn) in damages for copying features of the iPad and iPhone in its Galaxy range of devices.\n",
      "SPACY\n",
      "\"\n",
      "In August, Samsung lost a US patent case to Apple and was ordered to pay its rival $1.05bn (£0.66bn) in damages for copying features of the iPad and iPhone in its Galaxy range of devices.\n",
      "\n",
      "SENTENCE 4\n",
      "NLTK\n",
      "Samsung, which is the world's top mobile phone maker, is appealing the ruling.\n",
      "SPACY\n",
      "Samsung, which is the world's top mobile phone maker, is appealing the ruling.\n",
      "\n",
      "\n",
      "SENTENCE 5\n",
      "NLTK\n",
      "A similar case in the UK found in Samsung's favour and ordered Apple to publish an apology making clear that the South Korean firm had not copied its iPad when designing its own devices.\n",
      "SPACY\n",
      "A similar case in the UK found in Samsung's favour and ordered Apple to publish an apology making clear that the South Korean firm had not copied its iPad when designing its own devices.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compares the sentence splitting between the two toolkits?\n",
    "\n",
    "doc = nlp(text)\n",
    "sents = list(doc.sents)\n",
    "\n",
    "for i in range(max(len(sents), len(sentences_nltk))):\n",
    "    print('SENTENCE', i)\n",
    "    print('NLTK')\n",
    "    print(sentences_nltk[i])\n",
    "    print('SPACY')\n",
    "    print(sents[i])\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.a.ii - Sentence Choice\n",
    "We chose to compare the first sentence, because it includes a URL, dates, named entities and punctuation, giving more \"edge cases\" to compare."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.a.iii - POS Tagging Differences\n",
    "Interestingly there do appear to be some differences between the two toolkits in their POS-tagging. Below are some that stood out:\n",
    "\n",
    "Firstly, NLTK does split the URL's \"https\" for example, marking it as a singular noun (NN) while spaCy does not. SpaCy sees the entire URL as a plural noun (NNS).\n",
    "Secondly, NLTK marks the \"to\" as its own class of \"to\", while spaCy marks it as a preposition (IN). This is because NLTK uses the Penn Treebank tagset, while spaCy uses the Universal Dependencies tagset.\n",
    "Thirdly, \"infringe\" is labeled as a verb (VB) by NLTK, while spaCy labels it as a verb in present tense that is not in the third person singular form. A slight difference, but one that is important to note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html\n",
      "\n",
      "Documents filed to the San Jose federal court in California on November 23 list six Samsung products running the \"Jelly Bean\" and \"Ice Cream Sandwich\" operating systems, which Apple claims infringe its patents. \n",
      "\n",
      "NLTK \n",
      " [('https', 'NN'), (':', ':'), ('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ'), ('Documents', 'NNS'), ('filed', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('San', 'NNP'), ('Jose', 'NNP'), ('federal', 'JJ'), ('court', 'NN'), ('in', 'IN'), ('California', 'NNP'), ('on', 'IN'), ('November', 'NNP'), ('23', 'CD'), ('list', 'NN'), ('six', 'CD'), ('Samsung', 'NNP'), ('products', 'NNS'), ('running', 'VBG'), ('the', 'DT'), ('``', '``'), ('Jelly', 'RB'), ('Bean', 'NNP'), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), ('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP'), (\"''\", \"''\"), ('operating', 'VBG'), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), ('Apple', 'NNP'), ('claims', 'VBZ'), ('infringe', 'VB'), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')]\n",
      "\n",
      "spaCy \n",
      " [('https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'NNS'), ('\\n\\n', '_SP'), ('Documents', 'NNS'), ('filed', 'VBD'), ('to', 'IN'), ('the', 'DT'), ('San', 'NNP'), ('Jose', 'NNP'), ('federal', 'JJ'), ('court', 'NN'), ('in', 'IN'), ('California', 'NNP'), ('on', 'IN'), ('November', 'NNP'), ('23', 'CD'), ('list', 'NN'), ('six', 'CD'), ('Samsung', 'NNP'), ('products', 'NNS'), ('running', 'VBG'), ('the', 'DT'), ('\"', '``'), ('Jelly', 'NNP'), ('Bean', 'NNP'), ('\"', \"''\"), ('and', 'CC'), ('\"', '``'), ('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NN'), ('\"', \"''\"), ('operating', 'NN'), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), ('Apple', 'NNP'), ('claims', 'VBZ'), ('infringe', 'VBP'), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.'), ('\\n', '_SP')]\n"
     ]
    }
   ],
   "source": [
    "SENTENCE_NUM = 0\n",
    "print('SENTENCE', sentences_nltk[SENTENCE_NUM], \"\\n\")\n",
    "\n",
    "# NLTK POS tagging from exercise 1a\n",
    "print(\"NLTK \\n\", pos_tags_per_sentence[SENTENCE_NUM])\n",
    "print()\n",
    "\n",
    "# combine the token and spacy pos tag in one list\n",
    "pos_tags = [(token.text, token.tag_) for token in sents[SENTENCE_NUM]]\n",
    "print(\"spaCy \\n\", pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 3b: Named Entity Recognition (NER)\n",
    "* Describe differences between the output from NLTK and spaCy for Named Entity Recognition. Which one do you think performs better?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.b NER Differences\n",
    "NLTK by default using the ne_chunk() function assigns a NER label to each branch in the nested tree. This causes it to for example label the sub-tree of \"San Jose\" as an ORGANISATION.\n",
    "\n",
    "SpaCy on the other hand uses the ner component to label each token with a NER label. This allows it to label \"San Jose\" as a GPE (geopolitical entity) which is the correct label.\n",
    "\n",
    "From this example one could draw the conclusion that spaCy seems to perform better, both in the fact that it is faster (which cannot be shown in this notebook) and that it is more accurate (with San Jose being a GPE and not an ORGANISATION)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK \n",
      " [Tree('S', [('https', 'NN'), (':', ':'), ('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ'), ('Documents', 'NNS'), ('filed', 'VBN'), ('to', 'TO'), ('the', 'DT'), Tree('ORGANIZATION', [('San', 'NNP'), ('Jose', 'NNP')]), ('federal', 'JJ'), ('court', 'NN'), ('in', 'IN'), Tree('GPE', [('California', 'NNP')]), ('on', 'IN'), ('November', 'NNP'), ('23', 'CD'), ('list', 'NN'), ('six', 'CD'), Tree('ORGANIZATION', [('Samsung', 'NNP')]), ('products', 'NNS'), ('running', 'VBG'), ('the', 'DT'), ('``', '``'), ('Jelly', 'RB'), Tree('GPE', [('Bean', 'NNP')]), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), ('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP'), (\"''\", \"''\"), ('operating', 'VBG'), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), Tree('PERSON', [('Apple', 'NNP')]), ('claims', 'VBZ'), ('infringe', 'VB'), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')])]\n",
      "\n",
      "spaCy \n",
      " [('https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'TIME'), ('\\n\\n', ''), ('Documents', ''), ('filed', ''), ('to', ''), ('the', ''), ('San', 'GPE'), ('Jose', 'GPE'), ('federal', ''), ('court', ''), ('in', ''), ('California', 'GPE'), ('on', ''), ('November', 'DATE'), ('23', 'DATE'), ('list', ''), ('six', 'CARDINAL'), ('Samsung', 'ORG'), ('products', ''), ('running', ''), ('the', 'LAW'), ('\"', 'LAW'), ('Jelly', 'LAW'), ('Bean', 'LAW'), ('\"', ''), ('and', ''), ('\"', ''), ('Ice', ''), ('Cream', ''), ('Sandwich', ''), ('\"', ''), ('operating', ''), ('systems', ''), (',', ''), ('which', ''), ('Apple', 'ORG'), ('claims', ''), ('infringe', ''), ('its', ''), ('patents', ''), ('.', ''), ('\\n', '')]\n"
     ]
    }
   ],
   "source": [
    "# NLTK NER tagging from exercise 1b\n",
    "print(\"NLTK \\n\", ner_tags_per_sentence[:1])  # only the first sentence as this is enough for comparison\n",
    "print()\n",
    "\n",
    "# SpaCy NER tagging\n",
    "ner_tags = [(token.text, token.ent_type_) for token in sents[SENTENCE_NUM]]\n",
    "print(\"spaCy \\n\", ner_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 3c: Constituency/dependency parsing\n",
    "Choose one sentence from the text and run constituency parsing using NLTK and dependency parsing using spaCy.\n",
    "* describe briefly the difference between constituency parsing and dependency parsing\n",
    "* describe differences between the output from NLTK and spaCy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.c.i - Difference Between Constituency Parsing and Dependency Parsing\n",
    "A dependency parser detects flat relations between adjectives, nouns and verbs, a consituency parser detects hierarchical relations such as noun phrases and verb phrases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.c.ii - Constituency Parsing using NLTK vs Dependency Parsing using spaCy\n",
    "Due to the fact that spaCy doesn't by default perform constituency parsing, it has to be kept in mind that different parsing methods are being compared here.\n",
    "For NLTK we have defined our own RegexParser, which is a constituency parser. For spaCy we are using the built-in dependency parser.\n",
    "\n",
    "NLTK finds the constituency relations between phrases in the tree structure, while spaCy shows the depenedency relations between the tokens in the sentence. This is why the output of the two parsers is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK \n",
      "\n",
      "[Tree('S', [Tree('NP', [('https', 'NN')]), (':', ':'), Tree('NP', [('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ')]), ('Documents', 'NNS'), Tree('VP', [Tree('V', [('filed', 'VBN')])]), ('to', 'TO'), Tree('NP', [('the', 'DT')]), Tree('ORGANIZATION', [('San', 'NNP'), ('Jose', 'NNP')]), Tree('NP', [('federal', 'JJ'), ('court', 'NN')]), Tree('P', [('in', 'IN')]), Tree('GPE', [('California', 'NNP')]), Tree('P', [('on', 'IN')]), ('November', 'NNP'), ('23', 'CD'), Tree('NP', [('list', 'NN')]), ('six', 'CD'), Tree('ORGANIZATION', [('Samsung', 'NNP')]), ('products', 'NNS'), Tree('VP', [Tree('V', [('running', 'VBG')]), Tree('NP', [('the', 'DT')])]), ('``', '``'), ('Jelly', 'RB'), Tree('GPE', [('Bean', 'NNP')]), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), Tree('NEP', [('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP')]), (\"''\", \"''\"), Tree('VP', [Tree('V', [('operating', 'VBG')])]), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), Tree('PERSON', [('Apple', 'NNP')]), Tree('VP', [Tree('V', [('claims', 'VBZ')])]), Tree('VP', [Tree('V', [('infringe', 'VB')])]), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')])]\n",
      "\n",
      "spaCy \n",
      "\n",
      "https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html -> amod -> Documents\n",
      "\n",
      "\n",
      " -> dep -> https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html\n",
      "Documents -> nsubj -> filed\n",
      "filed -> ROOT -> filed\n",
      "to -> prep -> filed\n",
      "the -> det -> court\n",
      "San -> nmod -> Jose\n",
      "Jose -> nmod -> court\n",
      "federal -> amod -> court\n",
      "court -> pobj -> to\n",
      "in -> prep -> court\n",
      "California -> pobj -> in\n",
      "on -> prep -> filed\n",
      "November -> pobj -> on\n",
      "23 -> nummod -> November\n",
      "list -> compound -> products\n",
      "six -> nummod -> products\n",
      "Samsung -> compound -> products\n",
      "products -> dobj -> filed\n",
      "running -> acl -> products\n",
      "the -> det -> Bean\n",
      "\" -> punct -> Bean\n",
      "Jelly -> compound -> Bean\n",
      "Bean -> dobj -> running\n",
      "\" -> punct -> Bean\n",
      "and -> cc -> Bean\n",
      "\" -> punct -> Sandwich\n",
      "Ice -> compound -> Cream\n",
      "Cream -> compound -> Sandwich\n",
      "Sandwich -> nmod -> systems\n",
      "\" -> punct -> Sandwich\n",
      "operating -> compound -> systems\n",
      "systems -> conj -> Bean\n",
      ", -> punct -> systems\n",
      "which -> nsubj -> infringe\n",
      "Apple -> compound -> claims\n",
      "claims -> nsubj -> infringe\n",
      "infringe -> relcl -> systems\n",
      "its -> poss -> patents\n",
      "patents -> dobj -> infringe\n",
      ". -> punct -> filed\n",
      "\n",
      " -> dep -> .\n"
     ]
    }
   ],
   "source": [
    "# NLTK constituency parsing from exercise 1c\n",
    "print(\"NLTK \\n\")\n",
    "print(constituency_v2_output_per_sentence[:1])\n",
    "print()\n",
    "\n",
    "# SpaCy dependency parsing\n",
    "print(\"spaCy \\n\")\n",
    "for token in list(doc.sents)[SENTENCE_NUM]:\n",
    "    print(token, \"->\", token.dep_, \"->\", token.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c2b566e8dec5b900dbd7511f2f553c4b7136e42c8ae04c7441430eeaa9a3e8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
